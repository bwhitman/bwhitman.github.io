---
title: "Google Instant Wrong"
date: "2017-03-08"
---

One of my favorite memories of The Echo Nest was when Google announced their “[Instant Mix](https://support.google.com/googleplay/answer/1186958?hl=en)” feature in 2011. It was the first public product of theirs that did anything close to what we had been shipping: automatic music suggestions based on similarity or a listeners’ profile. Back in the 2000s, Google was a constantly worrying presence to technology startups. Investors would always tell me that Google would “eat our lunch” one day, because they had the smartest people and the most data. And I knew most of the team that was working on music recommendations: in fact, I had tried to hire many of them and still would love to. (A large number of them worked on the recent amazing [AudioSet](https://research.google.com/audioset/) release.) So when Instant Mix was announced in a splash at their yearly conference, we immediately huddled around and gave it a spin. I’ll say this directly: _it was laughably terrible._ We thought it must have been a mistake, or they somehow knew our IP address and were serving us joke data, but everyone across the world was seeing these mostly random music suggestions based on the supposedly best in class “machine learning and audio processing.” My favorite was its suggestion that fans of Kraftwerk also check out Jack Johnson. The results stayed up for a while, were slightly tweaked and the feature slowly lost prominence in the UI over the years. 

https://twitter.com/plamere/status/795973585965879296

Paul sat down that week to write my favorite blog post of all time, “[How Good Is Google’s Instant Mix?](https://musicmachinery.com/2011/05/14/how-good-is-googles-instant-mix/)” In it, he coined the “WTF score” — perhaps the most obvious (and most successful) way to evaluate subjective quality given a list of results. A WTF score is a great tool because anyone can do it, it doesn’t require any user data, unit test SDKs or QA strategies, and it’s easy to present and stand by: “How many of these results are obviously wrong?” In music, particularly, many people die on the hill of the edge case: “I would put XTC closer to Talking Heads here, but only the early stuff” is sometimes valuable but not useful if you’re trying to evaluate large changes to a scalable recommender. Your finely honed respect for music shouldn’t be an asset to WTF QA. You can more simply say: “Everyone knows that Jack Johnson and Kraftwerk have nothing to do with each other”; you add a +1 to the WTF list, and move on to the next item. WTF scores, "the number of thing that are _obviously wrong_ from the set", were used as a first pass metric from then until the end of the meaningful life of Echo Nest, and it caught on at Spotify and continues there. 

This week the internet is en masse evaluating the WTF of another Google product. The [featured snippets](https://theoutline.com/post/1192/google-s-featured-snippets-are-worse-than-fake-news) that appear when you ask Google “factual” questions have been Google search staples for 3 years, but given new platforms in voice control and mobile, and through the lens of an irrational political cycle, are gaining real relevance and concern. I’ll share two short videos that made this NLP/information retrieval scientist _terribly angry_:

https://twitter.com/ruskin147/status/838445095410106368

https://twitter.com/dannysullivan/status/805418383713902592
